{"cells":[{"cell_type":"markdown","source":["# Getting Started with Azure Databricks\n\n**Technical Accomplishments:**\n- Set the stage for learning on the Databricks platform\n- Create the cluster\n- Discover the workspace, import table data\n- Demonstrate how to develop & execute code within a notebook\n- Review the various \"Magic Commands\"\n- Introduce the Databricks File System (DBFS)"],"metadata":{}},{"cell_type":"markdown","source":["## Attach notebook to your cluster\nBefore executing any cells in the notebook, you need to attach it to your cluster. Make sure that the cluster is running.\n\nIn the notebook's toolbar, select the drop down arrow next to Detached, and then select your cluster under Attach to."],"metadata":{}},{"cell_type":"markdown","source":["## Working with notebooks\n\nA notebook is a web-based interface to a document that contains \n* runnable code\n* visualizations\n* descriptive text\n\nTo create a notebook, click on `Workspace`, browse into the desired folder, right click and choose `Create` then select `Notebook`."],"metadata":{}},{"cell_type":"markdown","source":["A notebook contains multiple cells. Each cell has a specific type. \n\nA default programming language is configured when creating the notebook and it will be implicitly used for new cells.\n\n#### Magic commands\n\nWe can override the cell's default programming language by using one of the following *magic commands* at the start of the cell:\n\n* `%python` for cells running python code\n* `%scala` for cells running scala code\n* `%r` for cells running R code\n* `%sql` for cells running sql code\n  \nAdditional magic commands are available:\n\n* `%md` for descriptive cells using markdown\n* `%sh` for cells running shell commands\n* `%run` for cells running code defined in a separate notebook\n* `%fs` for cells running code that uses `dbutils` commands"],"metadata":{}},{"cell_type":"markdown","source":["To run a cell use one of the following options:\n  * **CTRL+ENTER** or **CMD+RETURN**\n  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>"],"metadata":{}},{"cell_type":"code","source":["#assuming the default language for a notebook was set to Python\nprint(\"I'm running Python!\")"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">I&#39;m running Python!\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Below we use a simple python function to convert Celsius degrees to Fahrenheit degrees."],"metadata":{}},{"cell_type":"code","source":["%python\n\n#convert celsius to fahrenheit\ndef celsiusToFahrenheit(source_temp=None):\n    return(source_temp * (9.0/5.0)) + 32.0    \n        \n#input values - celsius\na = [1, 2, 3, 4, 5]\nprint(a)\n\n#convert all\nb = map(lambda x: celsiusToFahrenheit(x), a)\nprint(list(b))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[1, 2, 3, 4, 5]\n[33.8, 35.6, 37.4, 39.2, 41.0]\n</div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["##![Spark Logo Tiny](https://files.training.databricks.com/images/wiki-book/general/logo_spark_tiny.png) Databricks File System - DBFS\n\nWe've already imported data into Databricks by uploading our files.\n\nDatabricks is capable of mounting external/remote datasources as well.\n\nDBFS allows you to mount storage objects so that you can seamlessly access data without requiring credentials.\nAllows you to interact with object storage using directory and file semantics instead of storage URLs.\nPersists files to object storage, so you wonâ€™t lose data after you terminate a cluster.\n\n* DBFS is a layer over a cloud-based object store\n* Files in DBFS are persisted to the object store\n* The lifetime of files in the DBFS are **NOT** tied to the lifetime of our cluster\n\nSee also <a href=\"https://docs.azuredatabricks.net/user-guide/dbfs-databricks-file-system.html\" target=\"_blank\">Databricks File System - DBFS</a>."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["### Databricks Utilities - dbutils\n* You can access the DBFS through the Databricks Utilities class (and other file IO routines).\n* An instance of DBUtils is already declared for us as `dbutils`."],"metadata":{}},{"cell_type":"markdown","source":["The `mount` command allows to use remote storage as if it were a local folder available in the Databricks workspace\n\n```\ndbutils.fs.mount(\n  source = f\"wasbs://dev@{data_storage_account_name}.blob.core.windows.net\",\n  mount_point = data_mount_point,\n  extra_configs = {f\"fs.azure.account.key.{data_storage_account_name}.blob.core.windows.net\": data_storage_account_key})\n```"],"metadata":{}},{"cell_type":"markdown","source":["To show available DBFS mounts:"],"metadata":{}},{"cell_type":"code","source":["%fs \nmounts"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td></td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td></td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td></td></tr></tbody></table></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["To show available tables:"],"metadata":{}},{"cell_type":"code","source":["%fs\nls /FileStore/tables"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/nyc_taxi-1.csv</td><td>nyc_taxi-1.csv</td><td>750682</td><td>1652615504000</td></tr><tr><td>dbfs:/FileStore/tables/nyc_taxi.csv</td><td>nyc_taxi.csv</td><td>750682</td><td>1652615318000</td></tr></tbody></table></div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["Additional help is available via `dbutils.help()` and for each sub-utility: `dbutils.fs.help()`, `dbutils.meta.help()`, `dbutils.notebook.help()`, `dbutils.widgets.help()`.\n\nSee also <a href=\"https://docs.azuredatabricks.net/user-guide/dbutils.html\" target=\"_blank\">Databricks Utilities - dbutils</a>"],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.help()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /><h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /></div>"]}}],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"Getting Started with Azure Databricks","notebookId":836836672563019},"nbformat":4,"nbformat_minor":0}